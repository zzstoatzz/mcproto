# Decentralized Reputation Models for MCP (AT Protocol Integration)

**Overview:** Designing a 0–1 reputation score in a decentralized environment requires combining diverse trust signals into a meaningful metric. Below we explore mathematical models for multi-factor reputation, normalization methods to yield a single 0-1 score, examples of decentralized reputation systems, and implementation considerations aligning with the AT Protocol. We also consider how AT Protocol’s existing features (decentralized identifiers, social graph, labels) can support or extend such a reputation system.

## Mathematical Models for Reputation

 ([image]()) *Schematic diagram of a Web-of-Trust showing direct trust (solid arrows) and indirect trust (through intermediaries). Decentralized reputation systems often leverage trust graphs where trust can propagate transitively through the network.* 

**Weighted Multi-Factor Aggregation:** A straightforward approach is to calculate a weighted score from multiple inputs (identity verification, usage stats, ratings, etc.). Each factor can be converted to a 0–1 sub-score and combined using assigned weights reflecting its importance. For example, a model might assign 0 or 1 for identity verification, use a success rate (0–1) for usage reliability, and incorporate average user ratings scaled to 0–1. The overall reputation *R* could be `R = w1*Identity + w2*Usage + w3*Rating + ...` with weights summing to 1. This produces a single normalized score and allows tuning the influence of each component. Traditional reputation systems like eBay essentially use a weighted aggregate of positive vs. negative feedback (yielding a percentage reputation) ([Trust Metrics - P2P Foundation](https://wiki.p2pfoundation.net/Trust_Metrics#:~:text=For%20example%2C%20Ebay%20and%20Pagerank,since%20trust%20cannot%20be%20objective)). The downside is that choosing weights is subjective – a community or governance process may be needed to set or adjust them democratically.

**Probabilistic Trust Models:** Another approach is to treat reputation as a probability of trustworthy behavior. Bayesian reputation systems (e.g. the “Beta reputation system”) do this by modeling positive/negative feedback as evidence updating a Beta distribution ([[PDF] The Beta Reputation System - Semantic Scholar](https://www.semanticscholar.org/paper/The-Beta-Reputation-System-Ismail-J%C3%B8sang/b451a8a074f61fe7f019dc7f8c3262636d4a7b7d#:~:text=Scholar%20www,presented%2C%20which%20represents%20a)). Each successful interaction increases a peer’s *alpha* (positive evidence) and each failure increases *beta* (negative evidence); the reputation score can be the expected probability of success = α/(α+β) (often after initializing with α=β=1 as a prior) ([EigenTrust - Wikipedia](https://en.wikipedia.org/wiki/EigenTrust#:~:text=where%20sat%20,has%20received%20from%20peer%20j)). This naturally yields a 0–1 score representing the likelihood a peer is trustworthy. Such probabilistic models weight more data heavily – a service with 100 successes and 5 failures (α=101, β=6) will have a high score (~0.94) and also high confidence. They are robust in that more interactions tighten the distribution (reducing uncertainty). Bayesian trust models can also incorporate forgetting factors or confidence intervals. The Beta reputation technique is common in P2P networks and sensor networks to combine binary outcomes into a single trust probability ([[PDF] The Beta Reputation System - Semantic Scholar](https://www.semanticscholar.org/paper/The-Beta-Reputation-System-Ismail-J%C3%B8sang/b451a8a074f61fe7f019dc7f8c3262636d4a7b7d#:~:text=Scholar%20www,presented%2C%20which%20represents%20a)).

**Graph-Based and Transitive Trust Models:** Decentralized settings often leverage the social graph or peer-to-peer network for reputation propagation. In *transitive trust* models, trust can flow through connections: if Alice trusts Bob, and Bob trusts Carol, then Alice gains some trust in Carol indirectly ([EigenTrust - Wikipedia](https://en.wikipedia.org/wiki/EigenTrust#:~:text=The%20Eigentrust%20algorithm%20is%20based,transactions%20that%20it%20has%20had)). The **EigenTrust** algorithm is a famous example, computing global reputations in a P2P network by aggregating local trust values and iteratively propagating trust scores across the network ([EigenTrust - Wikipedia](https://en.wikipedia.org/wiki/EigenTrust#:~:text=The%20local%20trust%20values%20are,peer%20i%20places%20in%20them)) ([EigenTrust - Wikipedia](https://en.wikipedia.org/wiki/EigenTrust#:~:text=If%20we%20assume%20that%20a,ik%7D%7D%20is%20given%20by)). Each peer *i* rates others based on past interactions (e.g. satisfactory minus unsatisfactory interactions) to form local scores s_ij ([EigenTrust - Wikipedia](https://en.wikipedia.org/wiki/EigenTrust#:~:text=The%20Eigentrust%20algorithm%20is%20based,transactions%20that%20it%20has%20had)). These local scores are normalized and treated as edges in a trust matrix ([EigenTrust - Wikipedia](https://en.wikipedia.org/wiki/EigenTrust#:~:text=The%20local%20value%20is%20normalized%2C,value%20c%20ij%20is%20then)). By repeatedly multiplying and converging (much like PageRank), EigenTrust yields a stable global trust value for each peer ([EigenTrust - Wikipedia](https://en.wikipedia.org/wiki/EigenTrust#:~:text=If%20we%20assume%20that%20a,ik%7D%7D%20is%20given%20by)). The idea is that a peer is trustworthy if trusted by other trustworthy peers – effectively an eigenvector centrality on the trust graph. Similarly, the **Advogato** trust metric uses a flow algorithm from a set of seed “trusted” identities to assign trust levels in a network ([security - An algorithm for distributed or decentralised reputation/trust - Stack Overflow](https://stackoverflow.com/questions/1002952/an-algorithm-for-distributed-or-decentralised-reputation-trust#:~:text=The%20web%20site%20Advogato%20implements,description%20of%20the%20trust%20metric)). Another modern example is **SourceCred’s CredRank**, which builds a contribution graph and runs a modified PageRank algorithm to assign a reputation score (“Cred”) to users based on how their contributions are endorsed in a community ([❓ FAQ | SourceCred](https://sourcecred.io/docs/beta/faq/#:~:text=What%20is%20a%20Contribution%20Graph%3F)). Graph-based models capture *network effects*: who trusts you (and how trusted *they* are) matters. They are powerful in leveraging social proof, but need safeguards against Sybil attacks (fake nodes colluding to boost trust). Many such models include damping factors or require that trust links themselves be earned. For instance, SourceCred’s PageRank-style algorithm has built-in resistance to Sybil attacks and allows tuning weights/heuristics to reduce gaming ([❓ FAQ | SourceCred](https://sourcecred.io/docs/beta/faq/#:~:text=SourceCred%20strives%20to%20be%20as,trust%20communities%2C%20where)).

Each approach can be combined or used in hybrid ways. For example, one might use a Bayesian update for direct interaction outcomes, and then incorporate social trust propagation for users who haven’t interacted directly. Indeed, academic literature often proposes blending direct and indirect reputation: direct experiences provide a base score, and network-based trust adjusts it based on the company one keeps ([A sample trust network | Download Scientific Diagram](https://www.researchgate.net/figure/A-sample-trust-network_fig1_221205333#:~:text=...%20as,)) ([A sample trust network | Download Scientific Diagram](https://www.researchgate.net/figure/A-sample-trust-network_fig1_221205333#:~:text=,)). The key is to ensure the scoring model is **meaningful** – reflecting relevant factors – and **robust** against manipulation (e.g. weighting many trivial ratings less, preventing Sybils, etc.).

## Normalizing to a 0–1 Trust Score

Because the reputation inputs are heterogeneous (binary verified status, counts of followers, percentages of successes, user star ratings, etc.), normalization is critical to produce a single 0–1 scale. Common techniques include:

- **Min-Max Scaling:** Transform each factor to a 0–1 range based on observed min/max or logical bounds ([How to normalize data to 0-1 range? - Cross Validated](https://stats.stackexchange.com/questions/70801/how-to-normalize-data-to-0-1-range#:~:text=Validated%20stats,x)). For example, if “longevity” (service age) ranges from 0 to 2 years, one could map 0 years → 0.0, 2+ years → 1.0 (with linear interpolation in between). This ensures each dimension contributes comparably.

- **Ratio or Percentage Measures:** Many metrics are naturally 0–1 (or can be). For instance, successful calls out of total calls is a success rate in [0,1]. User ratings average can be divided by the max rating (e.g. 4.5/5 stars → 0.9). These percentages serve as normalized inputs.

- **Z-scores or Logistic Scaling:** In cases with heavy-tailed distributions (like follower counts), a non-linear normalization can be used so that extremely high values don’t skew the scale. For example, one could take `score = 1 - exp(-X)` for something like uptime days, which approaches 1 asymptotically, or use a logistic function to compress a wide range into (0,1). The goal is to avoid one factor with an outsize range dominating the combined score.

- **Weighted Combination Normalization:** If using a weighted sum of factors, one can normalize by the sum of weights (which if set to 1 ensures the result is already 0–1 assuming each factor was 0–1). For instance, with weights summing to 1, a perfect score in all factors yields 1.0. If factors are not equally trustworthy, the weights themselves act as a normalization, down-weighting less reliable metrics.

Crucially, any **composite reputation formula** should be designed so that the maximum possible score is 1.0 (e.g. a fully verified, long-running service with stellar ratings), and the minimum is 0.0 (e.g. an unverified new service with poor or no track record). In practice, one might rarely see the extremes; the 0–1 scale is more about comparability. Some systems also define thresholds or categories (e.g. scores 0.8+ = “trusted”, below 0.3 = “low trust”). It’s worth noting that some decentralized trust frameworks even allow *negative* trust to denote active distrust ([Web of Trust Primitives | Chain Agnostic Improvement Proposals](https://chainagnostic.org/CAIPs/caip-261#specification#:~:text=trust%20score%3B%20,to%20process%20the%20trust%20score)), but if we constrain to 0–1, we treat distrust as simply a low score near 0. Techniques like EigenTrust’s local normalization (dividing by the sum of positive interactions) are effective to clamp values into bounds ([EigenTrust - Wikipedia](https://en.wikipedia.org/wiki/EigenTrust#:~:text=The%20local%20value%20is%20normalized%2C,value%20c%20ij%20is%20then)). Overall, careful normalization lets us combine apples and oranges (different metrics) into a single fruit salad of reputation, on which we can consistently reason.

## Examples of Decentralized Reputation Systems

To ground the design, it helps to examine existing reputation systems in decentralized or peer-to-peer contexts:

- **EigenTrust (P2P Networks):** EigenTrust (2003) is a seminal algorithm for global reputation in peer-to-peer filesharing networks ([EigenTrust - Wikipedia](https://en.wikipedia.org/wiki/EigenTrust#:~:text=EigenTrust%20algorithm%20%20is%20a,2)). Peers rate each transaction (was the file from peer **j** good or fake?), accumulate a local trust score for others, then those scores are normalized and aggregated network-wide. The aggregation uses an iterative eigenvector computation – effectively each peer asks its friends “what do you think of X?” and weights those opinions by how much it trusts those friends ([EigenTrust - Wikipedia](https://en.wikipedia.org/wiki/EigenTrust#:~:text=The%20local%20trust%20values%20are,peer%20i%20places%20in%20them)). The result is a unique trust value per peer that all can reference. EigenTrust significantly reduced inauthentic files in simulations ([EigenTrust - Wikipedia](https://en.wikipedia.org/wiki/EigenTrust#:~:text=Hector%20Garcia,2)). Its math ensures *transitive trust*: if i trusts j and j trusts k, i will indirectly trust k (though less strongly) ([A sample trust network | Download Scientific Diagram](https://www.researchgate.net/figure/A-sample-trust-network_fig1_221205333#:~:text=,)). EigenTrust assumes a semi-central process to compute the final scores (or a distributed approximation), and it requires strategies to handle newcomers and collusion. Nonetheless, it provides a blueprint for computing reputation from distributed feedback in a robust way.

- **Advogato (Web of Trust):** Advogato was an early community blogging platform that implemented a *distributed trust metric*. It seeded the trust graph with a few known reputable users and used a max-flow algorithm to determine how trust flows out through user-issued certifications ([[PDF] A comparison of two trust metrics - Jesse Ruderman](https://www.squarefree.com/trust/trust.pdf#:~:text=Advogato%20uses%20the%20Ford,seed%2C%20any%20node%20with)) ([security - An algorithm for distributed or decentralised reputation/trust - Stack Overflow](https://stackoverflow.com/questions/1002952/an-algorithm-for-distributed-or-decentralised-reputation-trust#:~:text=The%20web%20site%20Advogato%20implements,description%20of%20the%20trust%20metric)). Users were classified into trust levels (e.g. “Master”, “Journeyer”) based on how far the trust flow from seeds could reach them. The system was designed to be attack-resistant, limiting how fake accounts could elevate each other. While Advogato’s specific algorithm yields categorical levels rather than a 0–1 score, the concept of *network flow-based reputation* is applicable – one could interpret the fraction of flow received as a 0–1 trust strength. This is essentially another way to propagate trust on a graph, similar in spirit to PageRank or EigenTrust but with a flow cutoff mechanism.

- **SourceCred (Cred for Contributions):** **SourceCred** is a Web3/community project that assigns “Cred” scores to contributors in decentralized projects. It builds a **Contribution Graph** of users and contributions (posts, commits, etc.), then applies a modified PageRank algorithm to distribute influence/credit through that graph ([❓ FAQ | SourceCred](https://sourcecred.io/docs/beta/faq/#:~:text=What%20is%20a%20Contribution%20Graph%3F)). For example, if Alice’s post is liked by many, that post gets high Cred, which then flows back to Alice. SourceCred’s algorithm (sometimes called *CredRank*) iteratively computes scores, and it mints new Cred when contributions receive positive feedback (like upvotes) ([❓ FAQ | SourceCred](https://sourcecred.io/docs/beta/faq/#:~:text=If%20a%20contribution%20is%20valuable%2C,other%20ponds%20downstream%20of%20it)). The scores are relative and can be normalized per community. Importantly, SourceCred is **configurable**: communities can adjust weights (e.g. how much a GitHub contribution vs. a forum post should count) and the system has safeguards against gaming – it’s transparent, and changes in behavior retroactively adjust Cred, discouraging users from exploiting short-term tricks ([❓ FAQ | SourceCred](https://sourcecred.io/docs/beta/faq/#:~:text=SourceCred%20strives%20to%20be%20as,trust%20communities%2C%20where)). While SourceCred is not a general-purpose identity reputation system (it’s more about rewarding work), its use of a decentralized, weighted graph algorithm and the concept of **non-transferable reputation (“Cred cannot be bought, only earned” ([❓ FAQ | SourceCred](https://sourcecred.io/docs/beta/faq/#:~:text=Cred%20is%20a%20score%20that,needs%20of%20an%20individual%20project)))** align with the goals of a trust metric for MCP. It shows that PageRank-style reputation can be tuned to specific use-cases and governed by the community using it.

- **Web3 Identity and “Cred” Projects:** Beyond SourceCred, various blockchain projects aim to create portable reputation. For instance, **BrightID** focuses on proof of uniqueness (to mitigate Sybils), and others like **Cred Protocol** (not to be confused with SourceCred) have explored on-chain credit scores. The *Web of Trust Primitives* proposal (CAIP-261) defines a data format for peers to issue **trust assertions** and compute reputation scores from a graph of trust ([Web of Trust Primitives | Chain Agnostic Improvement Proposals](https://chainagnostic.org/CAIPs/caip-261#specification#:~:text=Webs%20of%20trust%20form%20peer,scores%20by%20using%20graph%20theory)) ([Web of Trust Primitives | Chain Agnostic Improvement Proposals](https://chainagnostic.org/CAIPs/caip-261#specification#:~:text=,%7D%20%7D%2C%20proof%3A)). They envision using algorithms like EigenTrust to compute a trust score and packaging it as a verifiable credential attached to a DID ([Web of Trust Primitives | Chain Agnostic Improvement Proposals](https://chainagnostic.org/CAIPs/caip-261#specification#:~:text=,27T10%3A28%3A00.000Z%22%2C%20%22trustScoreType%22%3A%20%22EigenTrust%22%20%7D)). This indicates a trend: use decentralized identity infrastructure (DIDs) plus graph algorithms to make reputation portable across platforms. Additionally, decentralized marketplaces like OpenBazaar experimented with reputation systems where buyers and sellers rate each other, storing ratings on a blockchain or DHT. Many such systems ended up using simplified approaches (averages of ratings) due to complexity of fully decentralized trust, but they highlight the need for *contextual* reputation (a user might be high-rated as a seller but low-rated as a buyer, etc.). For MCP, focusing on the context of “model provider” reputation is key – we aggregate factors relevant to being a good model host.

In summary, numerous decentralized reputation frameworks (EigenTrust, Advogato, SourceCred, etc.) demonstrate techniques like trust transitivity, global versus local scoring, and community moderation of the reputation algorithm. These inform how we might design an MCP reputation: for example, using a **global trust metric** (everyone sees roughly the same 0–1 score for a given server, as in EigenTrust or eBay) versus a **personalized trust metric** (each user’s view of reputation might differ based on whose opinions they trust, as in some Web-of-Trust models ([Trust Metrics - P2P Foundation](https://wiki.p2pfoundation.net/Trust_Metrics#:~:text=Local%20vs)) ([Trust Metrics - P2P Foundation](https://wiki.p2pfoundation.net/Trust_Metrics#:~:text=Local%20trust%20metrics%20start%20from,statements%20from%20the%20other%20users))). A global score is simpler for MCP’s purposes, but it could be enriched by allowing users to weight certain inputs differently if needed.

## Implementation Considerations in a Decentralized Context

Designing the reputation system for MCP servers on the AT Protocol raises practical questions: how to gather signals from across the network, compute scores without a central authority, and integrate with AT Protocol’s architecture.

- **Aggregating Multi-Source Signals:** In a decentralized network, different aspects of reputation may be reported by different parties. For example, the MCP server itself can report usage statistics (e.g. number of successful calls, uptime), while users of the model can provide ratings or feedback entries. The AT Protocol’s **labeling system** is well-suited for this ([Labels - AT Protocol](https://atproto.com/specs/label#:~:text=Labels%20are%20a%20form%20of,content%20in%20the%20atproto%20ecosystem)) ([Labels - AT Protocol](https://atproto.com/specs/label#:~:text=The%20label%20concept%20and%20protocol,other%20purposes%20in%20atproto%20applications)). A label is basically a signed metadata tag about an account or content. Various actors could issue labels about a server’s trustworthiness – e.g. a monitoring service could label a server with “uptime: 99%” or “response-quality: high”, users could label “rating:4/5”, and a verification service could label “identity: verified”. These labels are published as atproto records and can be fetched by any aggregator. The reputation model then needs to consume these distributed signals and combine them. This could happen client-side (each user’s app collects all relevant labels and computes the 0–1 score for a server) or via a specialized **reputation service** that gathers data network-wide and offers computed scores (likely also via labels or a public feed). The key is that the computation doesn’t rely on any *single* authoritative database – it should use the openly available data on the network. For trust in social connections, the follow graph in AT Protocol is global and queryable, so an algorithm like EigenTrust or PageRank can be run over the follow network or a “trust link” network (if users explicitly publish whom they trust) to derive reputations. This is analogous to how Bluesky feed algorithms work on the open social graph. In short, the architecture should treat reputation inputs as *content on the network*, which multiple servers or clients can independently analyze to reach similar conclusions.

- **Decentralization and Avoiding Single Authority:** A major challenge is to avoid introducing a centralized oracle of reputation. The system should allow **open participation** in providing and auditing reputation signals. One approach is to have multiple independent reputation providers: e.g. different organizations or community groups could run their own reputation computations (with perhaps varying formulas) and publish scores. An end-user’s client might then take an average or consult a majority of these sources to decide a server’s trust score, akin to how multiple block explorers or certificate authorities work to increase confidence. Another approach is to bake consensus into the process: for instance, using a blockchain or distributed ledger to record ratings and maybe even compute a final score via a smart contract. However, introducing a blockchain might conflict with AT Proto’s architecture (which is not blockchain-based). Instead, leveraging AT’s existing **data repositories** and event streams might suffice. It’s also wise to keep the algorithm transparent – as recommended in one decentralized trust proposal, *“calculations made using the trust graph SHOULD be fully provable, with all input data and the computation method disclosed”* ([Web of Trust Primitives | Chain Agnostic Improvement Proposals](https://chainagnostic.org/CAIPs/caip-261#specification#:~:text=However%2C%20this%20specification%20offers%20some,of%20the%20trust%20graph%20information)). This transparency allows anyone to verify the scores and mitigates concerns of hidden bias. The community can scrutinize the method and suggest adjustments. In essence, the reputation system should be *algorithmically decentralized* (no secrets, no single controller of logic) even if some nodes perform the heavy lifting of computation.

- **Democratic Tuning and Governance:** Tying into the above, the model should allow democratic adjustments. Over time, the community may observe that certain signals are being abused (for example, attackers might script fake “follower” relationships to appear reputable, or orchestrate rating spam). The reputation algorithm must be adjustable – e.g. lowering the weight of easy-to-fake metrics, or incorporating new signals (perhaps a report of compliance or audit results). In a decentralized setting, changes can be proposed and discussed openly, and because the implementation is open, any trusted party can implement a variant. SourceCred provides a good analogy, where communities set their own weights and cannot directly edit scores except by changing the rules for everyone ([❓ FAQ | SourceCred](https://sourcecred.io/docs/beta/faq/#:~:text=Can%20I%20manually%20edit%20Cred,scores%20for%20Participants)). In the MCP context, one could imagine a consortium of model hosts and consumers forming a working group to govern the reputation formula. The AT Protocol’s **label** primitives again help here: one could switch which label sources they trust. For example, if a certain reputation service becomes too lenient, users could choose to ignore its labels and rely on an alternative service’s labels. This creates a **market of reputation providers**, fostering competition to provide the most accurate trust assessments. The absence of a single authority means malicious actors cannot simply “bribe the boss” to get a good reputation – they would have to fool the broader network, which is much harder.

- **AT Protocol Integration:** The design should leverage AT Proto’s **decentralized identity (DID)** system and other features. Every user or server on AT has a DID (e.g. `did:plc:...`) which is portable and not tied permanently to a single host. Reputation should likely attach to the DID (so if a server moves from one PDS to another, its reputation follows). AT Proto supports **domain verified handles** – if a server’s handle is a domain name it controls (e.g. `model.example.com`), that is a strong signal of accountability. The reputation algorithm can give a boost for domain-verified identity vs. a default handle, since an established domain suggests the operator is serious (this is analogous to the way domain verification adds trust in Bluesky). The social graph is directly usable: follows could be interpreted as endorsements (though not all follows mean trust, one might filter to follows from already reputable accounts). One could incorporate a PageRank on the follower graph as one component of the score, or simply use follower count with diminishing returns. AT Protocol also has a **label-based moderation** system where servers and community moderators label accounts for spam, harassment, etc. If a server has been labeled negatively by many reputable sources, the reputation system should take that into account (perhaps capping the max reputation of an account marked as “spam” by a trusted labeler). Conversely, if a server consistently posts helpful content and gains “helpful” labels, that could feed a positive reputation. Another existing mechanism is the rate-limiting of new servers in the Bluesky network: new Personal Data Servers are initially restricted in the data they can send until they prove themselves. *“As trust and reputation is established with PDS hosts, those rate limits will increase,”* the Bluesky team notes ([7 posts tagged with "guide" | Bluesky](https://docs.bsky.app/blog/tags/guide#:~:text=As%20with%20many%20open%20systems%2C,for%20detecting%20and%20mitigating%20abuse)). This implies that over time, a server earns a form of reputation in the network’s eyes (likely based on its behavior – not spewing spam, staying online consistently, etc.). We can piggyback on such signals: longevity and consistent operation can be measured (a simple metric: how long the DID has existed and how continuously the server has been active). A longer track record without issues should translate to a higher trust score.

- **Ensuring Robustness:** In implementing the reputation model, careful attention must be paid to **sybil attacks** (fake identities) and **collusion**. The AT Protocol’s invite-based growth and DIDs help here (it’s harder to create thousands of fake reputable servers if each needs a valid DID and handle). Still, the model should possibly incorporate **penalization for obvious sybils** (e.g. 100 new servers all following each other in a clique could be detected by graph analysis and not inflate each other’s scores much). Using multiple independent factors (identity, usage, social, feedback) inherently makes it harder to game everything at once – an attacker might fake one aspect but likely can’t fake them all without detection. For example, they might create fake followers, but they won’t have a years-long service history or a verified domain or genuine user reviews. By weighting a balanced basket of metrics, the reputation score can remain relatively resistant to any single vector of attack. Moreover, the model can incorporate negative feedback loops: if a previously good server suddenly starts failing or users report bad outputs, the score should drop quickly. And since in AT Protocol data is public, bad behavior can be quickly labeled and propagated as a warning.

- **Does AT Protocol Provide Any Native Reputation Mechanism?** Currently, AT Protocol itself does not define a built-in reputation score for accounts – it provides the **framework** (portable identities, rich social graphs, labels, etc.) to enable reputation systems to be built on top. There isn’t an official “trust score” field in one’s profile, for example. Instead, the emphasis is on modularity: communities or services can create their own reputation feeds. The protocol’s **lexicon** could allow defining a record type for “reputation report” if needed, or simply reuse labels (e.g. a label value like `trustScore.85` meaning 0.85). What *is* built-in is identity verification (DNS-based handle proofs) and a degree of network-level trust management (the relay limiting new servers until they earn trust, as mentioned). Those can be seen as seed inputs to a broader model. The Bluesky team has also discussed algorithmic ranking of content – while that’s about posts, not identities, similar principles (using the social graph and user feedback) apply. In sum, AT Protocol provides the *primitives* (DIDs, labels, social interconnection, open data) to implement a decentralized reputation system, but it’s up to app developers or the community to craft the algorithm. This is likely by design, to avoid imposing a one-size-fits-all reputation system at the protocol level. Our approach for MCP can thus be an extension that lives at the application layer, using all the rich data AT makes available.

## Conclusion

A decentralized reputation model for MCP servers can draw on a rich history of trust and reputation research. By combining **multiple factors** (identity verification, usage reliability, user feedback, social connections, longevity) in a weighted or probabilistic way, we get a more complete and tamper-resistant picture of “trustworthiness” than any single metric alone. Techniques like EigenTrust and PageRank show how to compute global trust scores from local interactions, while modern Web3 projects illustrate the importance of **portability** and **community governance** of reputation. **Normalization** ensures these diverse inputs yield a coherent 0–1 score that is easy to interpret. Implementing this on the AT Protocol is feasible by leveraging DIDs for identity, the social graph for trust signals, and the labeling system for disseminating reputation data. The resulting reputation system would be **decentralized**, with no single point of control, and aligned with AT Protocol’s ethos of user empowerment. It can enhance the MCP ecosystem by giving users a quantifiable trust signal – for example, a client app might warn “This model server has a low reputation (0.2) – proceed with caution,” or preferentially route requests to higher-reputed servers. Such a system must remain adaptive: as attackers find new ways to game it, the community can adjust the dials. But with a solid foundation in proven models and AT Protocol’s infrastructure, a 0–1 reputation score for decentralized AI model servers is well within reach, providing an essential layer of trust in an open network.

**Sources:**

1. Kamvar et al., *The EigenTrust Algorithm for Reputation Management in P2P Networks* – Overview of a global trust computation algorithm ([EigenTrust - Wikipedia](https://en.wikipedia.org/wiki/EigenTrust#:~:text=The%20Eigentrust%20algorithm%20is%20based,transactions%20that%20it%20has%20had)) ([EigenTrust - Wikipedia](https://en.wikipedia.org/wiki/EigenTrust#:~:text=The%20local%20value%20is%20normalized%2C,value%20c%20ij%20is%20then)).  
2. Wikipedia – *EigenTrust* (reputation algorithm for P2P networks) ([EigenTrust - Wikipedia](https://en.wikipedia.org/wiki/EigenTrust#:~:text=If%20we%20assume%20that%20a,ik%7D%7D%20is%20given%20by)); *Trust Metrics* (P2P Foundation) on global vs local trust and examples like eBay and PageRank ([Trust Metrics - P2P Foundation](https://wiki.p2pfoundation.net/Trust_Metrics#:~:text=For%20example%2C%20Ebay%20and%20Pagerank,since%20trust%20cannot%20be%20objective)).  
3. SourceCred Documentation – PageRank-based **Cred** scoring for contributions, with Sybil resistance and community tuning ([❓ FAQ | SourceCred](https://sourcecred.io/docs/beta/faq/#:~:text=What%20is%20a%20Contribution%20Graph%3F)) ([❓ FAQ | SourceCred](https://sourcecred.io/docs/beta/faq/#:~:text=SourceCred%20strives%20to%20be%20as,trust%20communities%2C%20where)).  
4. AT Protocol Specs – **Labels** (metadata tags for accounts/content) ([Labels - AT Protocol](https://atproto.com/specs/label#:~:text=Labels%20are%20a%20form%20of,content%20in%20the%20atproto%20ecosystem)) ([Labels - AT Protocol](https://atproto.com/specs/label#:~:text=The%20label%20concept%20and%20protocol,other%20purposes%20in%20atproto%20applications)) and Bluesky dev blog on PDS trust and rate limits ([7 posts tagged with "guide" | Bluesky](https://docs.bsky.app/blog/tags/guide#:~:text=As%20with%20many%20open%20systems%2C,for%20detecting%20and%20mitigating%20abuse)).  
5. ChainAgnostic CAIP-261 – Proposal for Web-of-Trust and reputation score credentials (trust scores, types, and transparency guidelines) ([Web of Trust Primitives | Chain Agnostic Improvement Proposals](https://chainagnostic.org/CAIPs/caip-261#specification#:~:text=trust%20score%3B%20,to%20process%20the%20trust%20score)) ([Web of Trust Primitives | Chain Agnostic Improvement Proposals](https://chainagnostic.org/CAIPs/caip-261#specification#:~:text=,%7D%20%7D%2C%20proof%3A)).  
6. Advogato and Web-of-Trust discussions – Early distributed trust metric using network flow ([[PDF] A comparison of two trust metrics - Jesse Ruderman](https://www.squarefree.com/trust/trust.pdf#:~:text=Advogato%20uses%20the%20Ford,seed%2C%20any%20node%20with)) ([security - An algorithm for distributed or decentralised reputation/trust - Stack Overflow](https://stackoverflow.com/questions/1002952/an-algorithm-for-distributed-or-decentralised-reputation-trust#:~:text=The%20web%20site%20Advogato%20implements,description%20of%20the%20trust%20metric)).